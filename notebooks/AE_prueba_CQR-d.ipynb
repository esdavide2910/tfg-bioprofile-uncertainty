{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e397b201",
   "metadata": {},
   "source": [
    "# PRUEBA CQR-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ba654fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca para aprendizaje profundo\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# \n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\n",
    "        \"CUDA no está disponible. PyTorch no reconoce la GPU.\"\n",
    "    )\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab22add6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/homeGPU/dgonzalez/tfg-bioprofile-uncertainty\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "working_dir = os.getcwd()\n",
    "print(working_dir)\n",
    "data_dir = working_dir + \"/data/AE_maxillofacial/preprocessed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0556e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo del sistema\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"src/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d286560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de argumentos de línea de comandos\n",
    "import argparse\n",
    "\n",
    "# Control de advertencias\n",
    "import warnings\n",
    "\n",
    "# Manipulación de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Manejo y edición de imágenes\n",
    "from PIL import Image\n",
    "\n",
    "# Visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Operaciones aleatorias\n",
    "import random\n",
    "\n",
    "# Funciones matemáticas avanzadas\n",
    "import math\n",
    "\n",
    "# Evaluación y partición de modelos\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Manejo de tiempo y fechas\n",
    "import time\n",
    "\n",
    "# Modelos y funciones de pérdida personalizados \n",
    "from custom_models import ResNeXtRegressor, QuantileLoss\n",
    "from coverage_metrics import empirical_coverage, mean_interval_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf14c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcd19bf7f50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una semilla de aleatoriedad \n",
    "SEED = 23\n",
    "\n",
    "# Fija la semilla para las operaciones aleatorias en Python puro\n",
    "random.seed(SEED)\n",
    "\n",
    "# Fija la semilla para las operaciones aleatorias en NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Fija la semilla para los generadores aleatorios de PyTorch en CPU\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Fija la semilla para todos los dispositivos GPU (todas las CUDA devices)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Desactiva la autooptimización de algoritmos en cudnn, que puede introducir no determinismo\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fuerza a cudnn a usar operaciones determinísticas (más lento pero reproducible)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Obliga a Pytorch a usar algoritmos determinísticos cuando hay alternativa. Si no la hay, lanza un error.\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Función auxiliar para asegurar que cada worker de DataLoader use una semilla basada en la global\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# Generador de números aleatorios para DataLoader\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23df25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define las transformaciones aplicadas a las imágenes durante el entrenamiento en cada época.\n",
    "# Estas transformaciones son aleatorias dentro de los rangos especificados, por lo que varían en cada época.\n",
    "# - Redimensiona las imágenes a 448x224. Se ha escogido este tamaño dado que las imágenes son panorámicas y \n",
    "#   bastante maś anchas que altas.\n",
    "# - (Regularización) Realiza un volteo horizontal a la mitad de las imágenes.\n",
    "# - (Regularización) Aplica una rotación aleatoria de hasta +/-3 grados.\n",
    "# - (Regularización) Aplica una transformación afín aleatoria con ligeras traslaciones (2%) y escalado (entre \n",
    "#   95% y 105%).\n",
    "# - (Regularización) Modifica aleatoriamente el brillo y contraste para simular condiciones de iluminación \n",
    "#   variables.\n",
    "# - Convierte la imagen a tensor, para que pueda ser manipulada por PyTorch.\n",
    "# - Normaliza para ajustar la media y desviación típica de los canales RGB a los valores usados durante el \n",
    "#   entrenamiento en ImageNet.\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.Resize((448, 224)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomRotation(degrees=3),\n",
    "     transforms.RandomAffine(degrees=0, translate=(0.02, 0.02), scale=(0.95, 1.05)), \n",
    "     transforms.ColorJitter(brightness=0.1, contrast=0.1), \n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]\n",
    ")\n",
    "\n",
    "# Define las transformaciones para las imágenes de validación y test, que son iguales que para entrenamiento \n",
    "# pero sin regularización\n",
    "valid_transform = test_transform = transforms.Compose(\n",
    "    [transforms.Resize((448, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72c6db5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxillofacialXRayDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, metadata_file, images_dir, transform=None):\n",
    "        \"\"\"\n",
    "        metadata_file: Ruta al fichero de metadatos (CSV u otro formato)\n",
    "        images_dir: Ruta al directorio de imágenes (entrenamiento o prueba)\n",
    "        transform: Transformaciones a aplicar a las imágenes (normalización, etc.)\n",
    "        \"\"\"\n",
    "        self.metadata = pd.read_csv(metadata_file)  # Cargar los metadatos\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Obteniene el nombre de la imagen y su valor desde los metadatos\n",
    "        img_name = os.path.join(self.images_dir, self.metadata.iloc[idx]['ID'])  # Ajusta según la estructura\n",
    "        target = self.metadata.iloc[idx]['Age'].astype(np.float32)  # Ajusta según el formato de tus metadatos\n",
    "        \n",
    "        # Abre la imagen\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # Aplica transformaciones si es necesario\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c414dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea el Dataset de entrenamiento con augmentations\n",
    "trainset = MaxillofacialXRayDataset(\n",
    "    metadata_file=data_dir + 'metadata_train.csv',\n",
    "    images_dir=data_dir + 'train/',\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "# Crea el Dataset de validación con solo resize y normalización \n",
    "validset = MaxillofacialXRayDataset(\n",
    "    metadata_file=data_dir + 'metadata_train.csv',  \n",
    "    images_dir=data_dir + 'train/',               \n",
    "    transform=valid_transform                       \n",
    ")\n",
    "\n",
    "# Crea el Dataset de test con solo resize y normalización\n",
    "testset  =  MaxillofacialXRayDataset(\n",
    "    metadata_file = data_dir + 'metadata_test.csv',\n",
    "    images_dir = data_dir + 'test/',\n",
    "    transform = test_transform\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1759fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establece un batch size de 32 \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Obtiene las edades enteras del trainset\n",
    "intAges = np.floor(trainset.metadata['Age'].astype(float).to_numpy()).astype(int)\n",
    "# Hay una única instancia con edad 26, que el algoritmo de separación de entrenamiento y validación será \n",
    "# incapaz de dividir de forma estratificada. Para evitar el error, reasigna esa instancia a la edad \n",
    "# inmediatamente inferior\n",
    "intAges[intAges==26]=25\n",
    "\n",
    "# Función auxiliar para crear un DataLoader a partir de un subconjunto del dataset\n",
    "def create_loader(dataset, indices):\n",
    "    subset = Subset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, \n",
    "                      pin_memory=True, worker_init_fn=seed_worker, generator=g)\n",
    " \n",
    "\n",
    "# Divide el conjunto de datos completo de entrenamiento en tres subconjuntos de forma estratificada:\n",
    "# - Entrenamiento (68% de las instancias)\n",
    "# - Validación (17% de las instancias)\n",
    "# - Calibración (15% de las instancias)\n",
    "\n",
    "train_idx, calib_idx = train_test_split(\n",
    "    range(len(trainset)), train_size=0.85, shuffle=True, stratify=intAges\n",
    ")\n",
    "\n",
    "train_idx, valid_idx = train_test_split(\n",
    "    train_idx, train_size=0.8, shuffle=True, stratify=[intAges[i] for i in train_idx]\n",
    ")\n",
    "\n",
    "train_loader = create_loader(trainset, train_idx)\n",
    "valid_loader = create_loader(validset, valid_idx)\n",
    "calib_loader = create_loader(validset, calib_idx)\n",
    "\n",
    "# Crea DataLoader de test\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49cb865f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "# Define los cuantiles que el modelo debe predecir (p.ej., 0.05 y 0.95 para 90% de confianza)\n",
    "quantiles = [alpha/2, 0.5, 1-alpha/2]\n",
    "\n",
    "# Inicializa el modelo con múltiples salidas, una por cada cuantil\n",
    "model = ResNeXtRegressor(len(quantiles)).to(device)\n",
    "\n",
    "#\n",
    "checkpoint = torch.load(\"models/AE_model04_CQR_90%.pth\", weights_only=False)\n",
    "\n",
    "# Carga los pesos del modelo \n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    model, dataloader, device='cuda', \n",
    "    return_targets=False, return_outputs=True, return_features=False\n",
    "):\n",
    "    # Pone la red en modo evaluación \n",
    "    model.eval()\n",
    "    \n",
    "    # Inicializa listas si son requeridas\n",
    "    all_targets = [] if return_targets else None\n",
    "    all_outputs = [] if return_outputs else None\n",
    "    all_features = [] if return_features else None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Soporta tanto (inputs, targets) como solo inputs\n",
    "            if isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
    "                inputs, targets = batch\n",
    "                inputs = inputs.to(device)\n",
    "                if return_targets:\n",
    "                    all_targets.append(targets.cpu())\n",
    "            else:\n",
    "                inputs = batch\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "            # Modelado según los flags\n",
    "            if return_features and return_outputs:\n",
    "                features, outputs = model(inputs, mode='both')\n",
    "                all_features.append(features.cpu())\n",
    "                all_outputs.append(outputs.cpu())\n",
    "            elif return_features:\n",
    "                features = model(inputs, mode='features')\n",
    "                all_features.append(features.cpu())\n",
    "            elif return_outputs:\n",
    "                outputs = model(inputs)\n",
    "                all_outputs.append(outputs.cpu())\n",
    "\n",
    "    # Concatena según sea necesario\n",
    "    result = []\n",
    "    if return_targets:\n",
    "        result.append(torch.cat(all_targets))\n",
    "    if return_features:\n",
    "        result.append(torch.cat(all_features))\n",
    "    if return_outputs:\n",
    "        result.append(torch.cat(all_outputs))\n",
    "\n",
    "    # Si solo hay un resultado, lo devuelve directamente\n",
    "    return result[0] if len(result) == 1 else tuple(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loader = test_loader\n",
    "\n",
    "# Obtiene valores verdaderos, características extraídas y valores predichos del conjunto de calibración \n",
    "calib_true_values, calib_features, calib_pred_values = \\\n",
    "    inference(model, calib_loader, return_targets=True, return_features=True)\n",
    "\n",
    "# Obtener características extraídas y valores predichos de las nuevas instancias\n",
    "new_true_values, new_features, new_pred_values = \\\n",
    "    inference(model, new_loader, return_targets=True, return_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5fb111e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=200\n",
    "\n",
    "# Calcula el nivel de cuantificación ajustado basado en el tamaño del conjunto de calibración y alpha\n",
    "n = len(calib_true_values)\n",
    "# global_q_level = np.ceil((1-alpha/2) * (n + 1)) / n\n",
    "global_q_level = 1.0 - alpha / 2.0\n",
    "\n",
    "# Calcula las conformity scores para los límites inferior y superior \n",
    "global_calib_scores_lower = calib_pred_values[:, 0] - calib_true_values # diferencia entre predicción inferior y valor real\n",
    "global_calib_scores_upper = calib_true_values - calib_pred_values[:,-1] # diferencia entre valor real y predicción superior\n",
    "\n",
    "# Calcula los cuantiles para ambos límites del intervalo predictivo\n",
    "global_quantile_lower = np.quantile(global_calib_scores_lower, global_q_level, method='higher')\n",
    "global_quantile_upper = np.quantile(global_calib_scores_upper, global_q_level, method='higher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cf92fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = calib_features.mean(dim=0, keepdim=True)\n",
    "std = calib_features.std(dim=0, keepdim=True)\n",
    "eps = 1e-6\n",
    "std = std.clamp_min(eps)\n",
    "\n",
    "new_features_std = (new_features - mean) / std\n",
    "calib_features_std = (calib_features - mean) / std\n",
    "\n",
    "dists = torch.cdist(new_features_std, calib_features_std, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bc3a3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_norm = F.normalize(new_features_std, p=2, dim=1)\n",
    "calib_norm = F.normalize(calib_features_std, p=2, dim=1)\n",
    "\n",
    "cos_sim = torch.matmul(new_norm, calib_norm.T)  # (N, M)\n",
    "dists = 1 - cos_sim  # (N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3acb97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_norm = F.normalize(new_features, p=2, dim=1)\n",
    "# calib_norm = F.normalize(calib_features, p=2, dim=1)\n",
    "# # cos_sim = torch.matmul(new_norm, calib_norm.T)  # (N, M)\n",
    "# # dists = 1 - cos_sim  # (N, M)\n",
    "# dists = torch.cdist(new_norm, calib_norm, p=2)\n",
    "\n",
    "\n",
    "\n",
    "# # Calcula las distancias entre las features de las nuevas instancias y las de calibración [N,M]\n",
    "# dists = torch.cdist(new_features, calib_features, p=2)\n",
    "\n",
    "# Obtiene los k vecinos en calibración más cercanos a cada instancia nueva [N,k]\n",
    "topk_dists, topk_idxs = torch.topk(dists, k=k, largest=False)\n",
    "\n",
    "# Calcula la densidad local como el inverso de la distancia media a los k vecinos más cercanos [N]\n",
    "local_density = 1.0 / topk_dists.mean(dim=1) # La densidad es mayor cuanto más cerca están los vecinos (0, +inf)\n",
    "\n",
    "# Calcula el peso local a partir de la densidad, mapeado entre 0 y 1 [N]\n",
    "local_weight = 1.0 - 1.0 / (1.0 + local_density) # El peso se acerca más a 0 cuanto más distintes están los vecinos, y más a 1 cuanto más cerca están\n",
    "\n",
    "# Calcula el peso global [N]\n",
    "global_weight = 1.0 - local_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a4f125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el nivel de cuantificación ajustado basado en el tamaño del conjunto de vecinos y alpha\n",
    "# local_q_level = np.ceil( (1.0 - alpha/2) * (k + 1) ) / k\n",
    "local_q_level = 1.0 - alpha / 2.0\n",
    "\n",
    "# Calcula las conformity scores para los límites inferior y superior en cada vecindario\n",
    "local_calib_scores_lower = calib_pred_values[topk_idxs, 0] - calib_true_values[topk_idxs]\n",
    "local_calib_scores_upper = calib_true_values[topk_idxs] - calib_pred_values[topk_idxs,-1]\n",
    "\n",
    "# Calcula los cuantiles qhat para ambos límites del intervalo predictivo\n",
    "local_quantile_lower = np.quantile(local_calib_scores_lower, local_q_level, method='higher')\n",
    "local_quantile_upper = np.quantile(local_calib_scores_upper, local_q_level, method='higher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6099eaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7414, 0.6121, 0.8280,  ..., 0.7282, 0.6696, 0.6962])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fc65d04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2586, 0.3879, 0.1720,  ..., 0.2718, 0.3304, 0.3038])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f3770a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda = 1.1\n",
    "\n",
    "# Calcula los cuantiles combinados\n",
    "comb_quantile_lower = (local_weight * local_quantile_lower + global_weight * global_quantile_lower) * lamda\n",
    "comb_quantile_upper = (local_weight * local_quantile_upper + global_weight * global_quantile_upper) * lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "32e0d485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cobertura empírica (para 90.0% de confianza): 88.708 %\n",
      "Tamaño medio del intervalo: 4.811\n"
     ]
    }
   ],
   "source": [
    "test_pred_lower = new_pred_values[:, 0] - comb_quantile_lower[:]\n",
    "test_pred_upper = new_pred_values[:,-1] + comb_quantile_upper[:]\n",
    "test_true_values = new_true_values\n",
    "\n",
    "# Calcula la cobertura empírica y lo imprime\n",
    "EC = empirical_coverage(test_pred_lower, test_pred_upper, test_true_values)\n",
    "print(f\"Cobertura empírica (para {(1-alpha)*100}% de confianza): {EC*100:>6.3f} %\")\n",
    "\n",
    "# Calcula el tamaño medio del intervalo de predicción y lo imprime\n",
    "MIS = mean_interval_size(test_pred_lower, test_pred_upper)\n",
    "print(f\"Tamaño medio del intervalo: {MIS:>5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfef95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
