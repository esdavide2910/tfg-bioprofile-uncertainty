{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e92faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE = 0.95\n",
    "ALPHA = 1-CONFIDENCE\n",
    "LOAD_MODEL_PATH = 'models/AGC_model02_LAC.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d06168e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath('src/'))\n",
    "working_dir = os.getcwd()\n",
    "data_dir = working_dir + '/data/AE_maxillofacial/preprocessed/'\n",
    "\n",
    "#\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "device = 'cuda'\n",
    "\n",
    "# Operaciones aleatorias\n",
    "import random\n",
    "\n",
    "# Manipulación de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Manejo y edición de imágenes\n",
    "from PIL import Image\n",
    "\n",
    "# Evaluación y partición de modelos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelos, funciones de pérdida y métricas personalizados \n",
    "from conformal_classification_models import *\n",
    "from cp_metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7212ce53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f666f5eb750>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determina la semilla\n",
    "SEED = 22\n",
    "\n",
    "# Fija la semilla para las operaciones aleatorias en Python puro\n",
    "random.seed(SEED)\n",
    "\n",
    "# Fija la semilla para las operaciones aleatorias en NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Fija la semilla para los generadores aleatorios de PyTorch en CPU\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Fija la semilla para todos los dispositivos GPU (todas las CUDA devices)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Desactiva la autooptimización de algoritmos en cudnn, que puede introducir no determinismo\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fuerza a cudnn a usar operaciones determinísticas (más lento pero reproducible)\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Obliga a Pytorch a usar algoritmos determinísticos cuando hay alternativa. Si no la hay, lanza un error.\n",
    "# torch.use_deterministic_algorithms(True)\n",
    "\n",
    "# Función auxiliar para asegurar que cada worker de DataLoader use una semilla basada en la global\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**SEED\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    " \n",
    "# Generador de números aleatorios para DataLoader\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cebb855",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [transforms.Resize((448, 224)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomRotation(degrees=3),\n",
    "     transforms.RandomAffine(degrees=0, translate=(0.02, 0.02), scale=(0.95, 1.05)), \n",
    "     transforms.ColorJitter(brightness=0.2, contrast=0.2), \n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize((448, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]\n",
    ")\n",
    "\n",
    "class MaxillofacialXRayDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, metadata_file, images_dir, transform=None):\n",
    "        \"\"\"\n",
    "        metadata_file: Ruta al fichero de metadatos (CSV u otro formato)\n",
    "        images_dir: Ruta al directorio de imágenes (entrenamiento o prueba)\n",
    "        transform: Transformaciones a aplicar a las imágenes (normalización, etc.)\n",
    "        \"\"\"\n",
    "        metadata = pd.read_csv(metadata_file)  \n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Preprocesar los campos una sola vez\n",
    "        self.img_paths = metadata['ID'].apply(lambda id_: os.path.join(images_dir, id_)).tolist()\n",
    "        \n",
    "        # Clasificación binaria de sexo: 1 para 'F' y 0 para 'M'\n",
    "        self.sexes = torch.tensor((metadata['Sex'] != 'M').astype(int).values, dtype=torch.long)\n",
    "        \n",
    "        # Edad en float\n",
    "        self.ages = torch.tensor(metadata['Age'].values, dtype=torch.float32)\n",
    "        \n",
    "        # Edad como enteros (en años completos)\n",
    "        metadata['IntAge'] = metadata['Age'].apply(lambda x: int(float(x)))\n",
    "        self.int_ages = torch.tensor(metadata['IntAge'].values, dtype=torch.long)\n",
    "        \n",
    "        # Obtener edades únicas ordenadas\n",
    "        unique_ages = sorted(metadata['IntAge'].unique())\n",
    "        self.age_to_idx = {age: idx for idx, age in enumerate(unique_ages)}\n",
    "        \n",
    "        # Mapear cada edad entera a su índice de clase\n",
    "        self.labels = torch.tensor(metadata['IntAge'].map(self.age_to_idx).values, dtype=torch.long)\n",
    "        \n",
    "        #\n",
    "        self.num_classes = len(unique_ages)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Carga la imagen\n",
    "        image = Image.open(self.img_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, self.labels[idx]\n",
    "\n",
    "\n",
    "# Crea el Dataset de entrenamiento con augmentations\n",
    "trainset = MaxillofacialXRayDataset(\n",
    "    metadata_file = data_dir + 'metadata_train.csv',\n",
    "    images_dir = data_dir + 'train/',\n",
    "    transform = train_transform\n",
    ")\n",
    "\n",
    "# Crea el Dataset de validación con solo resize y normalización \n",
    "validset = MaxillofacialXRayDataset(\n",
    "    metadata_file = data_dir + 'metadata_train.csv',\n",
    "    images_dir = data_dir + 'train/',\n",
    "    transform = test_transform\n",
    ")\n",
    "\n",
    "# Crea el Dataset de calibración con solo resize y normalización \n",
    "calibset = MaxillofacialXRayDataset(\n",
    "    metadata_file = data_dir + 'metadata_train.csv',\n",
    "    images_dir = data_dir + 'train/',\n",
    "    transform = test_transform\n",
    ")\n",
    "\n",
    "# Crea el Dataset de test con solo resize y normalización\n",
    "testset = MaxillofacialXRayDataset(\n",
    "    metadata_file = data_dir + 'metadata_test.csv',\n",
    "    images_dir = data_dir + 'test/',\n",
    "    transform = test_transform\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c015d7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establece un batch size de 32 \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Función optimizada para crear DataLoaders\n",
    "def create_loader(dataset, indices=None, shuffle=False, num_workers=1):\n",
    "    subset = Subset(dataset, indices) if indices is not None else dataset\n",
    "    return DataLoader(\n",
    "        subset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    )\n",
    "\n",
    "\n",
    "# Obtiene las edades del trainset por tramos de 0.5 años\n",
    "halfAges = (np.floor(trainset.ages.numpy() * 2) / 2).astype(np.float32)\n",
    "# Hay una única instancia con edad 26, que el algoritmo de separación de entrenamiento y validación será \n",
    "# incapaz de dividir de forma estratificada. Para evitar el error, reasigna esa instancia al tramo \n",
    "# inmediatamente inferior\n",
    "halfAges[halfAges == 26.0] = 25.5\n",
    "\n",
    "# Obtiene el sexo en binario\n",
    "sexes = trainset.sexes.numpy()\n",
    "\n",
    "# Crear etiquetas  combinadas de estratificación (p.ej.: \"18.0_M\", \"17.5_F\")\n",
    "stratify_labels = np.array([f\"{age:.1f}_{sex}\" for age, sex in zip(halfAges, sexes)])\n",
    "\n",
    "# Determina el número de hilos disponibles \n",
    "num_workers = int(os.environ.get(\"SLURM_CPUS_PER_TASK\", 1))\n",
    "\n",
    "# Divide el conjunto de datos completo de entrenamiento en tres subconjuntos de forma estratificada:\n",
    "# - Entrenamiento (68% de las instancias)\n",
    "# - Validación (17% de las instancias)\n",
    "# - Calibración (15% de las instancias)\n",
    "\n",
    "train_idx, calib_idx = train_test_split(range(len(trainset)), train_size=0.8, shuffle=True, \n",
    "                                        random_state=SEED, stratify=stratify_labels)\n",
    "\n",
    "train_idx, valid_idx = train_test_split(train_idx, train_size=0.8, shuffle=True, random_state=SEED,\n",
    "                                        stratify=[stratify_labels[i] for i in train_idx])\n",
    "\n",
    "train_loader = create_loader(trainset, train_idx, shuffle=True, num_workers=num_workers)\n",
    "valid_loader = create_loader(validset, valid_idx)\n",
    "calib_loader = create_loader(calibset, calib_idx)\n",
    "\n",
    "# Crea DataLoader de test\n",
    "test_loader = create_loader(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc1c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instancia el modelo con el nivel de confianza especificado y lo envía a la GPU\n",
    "model = ResNeXtClassifier_APS(num_classes=trainset.num_classes, confidence=CONFIDENCE).to(device)\n",
    "\n",
    "# Carga el checkpoint desde el archivo especificado \n",
    "checkpoint = torch.load(LOAD_MODEL_PATH, weights_only=False)\n",
    "\n",
    "# Carga el modelo\n",
    "model.load_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298e60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "model.set_temperature(valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5523b1b",
   "metadata": {},
   "source": [
    "### INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24805d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "calib_pred_scores, calib_true_labels  = model._inference(calib_loader, return_probs=True)\n",
    "test_pred_scores, test_true_labels = model._inference(test_loader, return_probs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171ce5f",
   "metadata": {},
   "source": [
    "### CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8f4329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c563f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9906558394432068\n"
     ]
    }
   ],
   "source": [
    "# Obtiene el número de instancias del conjunto\n",
    "n = len(calib_true_labels) \n",
    "\n",
    "# \n",
    "tau = 1-ALPHA\n",
    "\n",
    "# Ordena los scores de mayor a menor y calcula la suma acumulada\n",
    "sorted_scores, sorted_class_index = torch.sort(calib_pred_scores, dim=1, descending=True)\n",
    "cumulative_scores = torch.cumsum(sorted_scores, dim=1)\n",
    "\n",
    "# Encuentra el índice donde está la clase verdadera en la clasificación ordenada\n",
    "matches = (sorted_class_index == calib_true_labels.unsqueeze(1))\n",
    "true_class_rank = matches.float().argmax(dim=1)  # (n,)\n",
    "\n",
    "# Recolecta los scores y suma acumulada en la posición del índice verdadero\n",
    "true_score = sorted_scores[torch.arange(n), true_class_rank]\n",
    "true_cum_score = cumulative_scores[torch.arange(n), true_class_rank]\n",
    "\n",
    "if random:\n",
    "    \n",
    "    # Genera un vector de valores aleatorios entre 0 y 1, uno por instancia \n",
    "    U = torch.rand(n)\n",
    "    \n",
    "    # Calcula V\n",
    "    V = (true_cum_score - tau) / true_score\n",
    "\n",
    "    # 4. Calcula nonconformity_scores con indexado condicional\n",
    "    # Si U > V → usar cumulative_scores en true_class_rank\n",
    "    # Si U <= V → usar cumulative_scores en true_class_rank - 1\n",
    "\n",
    "    # Evita valores negativos en el índice\n",
    "    adjusted_rank = torch.clamp(true_class_rank - 1, min=0)\n",
    "\n",
    "    # Selección de valores según condición\n",
    "    nonconformity_scores = torch.where(\n",
    "        U <= V,\n",
    "        cumulative_scores[torch.arange(n), adjusted_rank],\n",
    "        true_cum_score\n",
    "    )\n",
    "    \n",
    "    print(len(nonconformity_scores[U<=V]))\n",
    "\n",
    "else:\n",
    "\n",
    "    nonconformity_scores = true_cum_score\n",
    "\n",
    "# \n",
    "q_level = math.ceil((1.0 - ALPHA) * (n + 1.0)) / n\n",
    "\n",
    "#\n",
    "q_hat = torch.quantile(nonconformity_scores, q_level, interpolation='higher').item()\n",
    "\n",
    "print(q_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e2874",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene el número de instancias del conjunto\n",
    "n, num_classes = test_pred_scores.shape\n",
    "\n",
    "# Determina la clase predicha como la clase con mayor puntuación\n",
    "_, test_pred_labels = torch.max(test_pred_scores, dim=1) \n",
    "\n",
    "# Ordena los scores de mayor a menor y calcula la suma acumulada\n",
    "sorted_scores, sorted_class_perm_index = torch.sort(test_pred_scores, dim=1, descending=True)\n",
    "cum_sorted_scores = torch.cumsum(sorted_scores, dim=1)\n",
    "\n",
    "# Obtiene el índice (0-indexed) de la última clase en el ranking que no supera el umbral de no conformidad\n",
    "matches = cum_sorted_scores <= q_hat\n",
    "has_match = matches.any(dim=1)\n",
    "last_class_ranks = torch.where(\n",
    "    has_match,\n",
    "    matches.int().sum(dim=1)-1,\n",
    "    torch.ones(n, dtype=torch.uint8)\n",
    ")\n",
    "\n",
    "if random:\n",
    "    # Genera un vector de valores aleatorios entre 0 y 1, uno por instancia \n",
    "    U = torch.rand(n)\n",
    "    \n",
    "    #\n",
    "    last_score = sorted_scores[torch.arange(n), last_class_ranks]\n",
    "    last_cum_scores = cum_sorted_scores[torch.arange(n), last_class_ranks]\n",
    "    \n",
    "    #\n",
    "    V = (last_cum_scores - q_hat) / last_score\n",
    "    \n",
    "    #\n",
    "    last_class_ranks = torch.where(\n",
    "        (U <= V) & (last_class_ranks>=1),\n",
    "        last_class_ranks-1,\n",
    "        last_class_ranks\n",
    "    )\n",
    "    \n",
    "    print(last_class_ranks[((U <= V) & (last_class_ranks>=1))==True])\n",
    "\n",
    "# Obtiene la máscara de inclusión ...\n",
    "idx = torch.arange(num_classes)\n",
    "inclusion_mask = idx <= last_class_ranks.unsqueeze(1)\n",
    "\n",
    "# \n",
    "test_pred_sets = torch.zeros_like(test_pred_scores, dtype=torch.uint8)\n",
    "test_pred_sets.scatter_(1, sorted_class_perm_index, inclusion_mask.to(torch.uint8))\n",
    "\n",
    "# Asegura que siempre haya al menos una clase en el conjunto predicho\n",
    "empty_sets = inclusion_mask.sum(dim=1) == 0\n",
    "test_pred_sets[empty_sets] = 1  # selecciona todas las clases en esos casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0ea2abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 25.60 %\n",
      "Cobertura empírica: 94.52 %\n",
      "Tamaño medio de conjunto: 6.22\n"
     ]
    }
   ],
   "source": [
    "# Calcula y muestra la exactitud\n",
    "accry = (test_pred_labels == test_true_labels).sum() / test_true_labels.size(0)\n",
    "print(f\"Accuracy: {accry*100:>4.2f} %\")\n",
    "\n",
    "# Calcula y muestra la cobertura empírica \n",
    "ec = empirical_coverage_classification(test_pred_sets, test_true_labels)\n",
    "print(f\"Cobertura empírica: {ec*100:>4.2f} %\")\n",
    "\n",
    "# Calcula y muestra el tamaño medio del conjunto\n",
    "mss = mean_set_size(test_pred_sets)\n",
    "print(f\"Tamaño medio de conjunto: {mss:>4.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "824477d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de etiquetas: 1, Instancias: 3, Cobertura: 66.67%\n",
      "Número de etiquetas: 2, Instancias: 120, Cobertura: 91.67%\n",
      "Número de etiquetas: 3, Instancias: 280, Cobertura: 87.50%\n",
      "Número de etiquetas: 4, Instancias: 148, Cobertura: 87.16%\n",
      "Número de etiquetas: 5, Instancias: 84, Cobertura: 96.43%\n",
      "Número de etiquetas: 6, Instancias: 301, Cobertura: 94.35%\n",
      "Número de etiquetas: 7, Instancias: 636, Cobertura: 96.70%\n",
      "Número de etiquetas: 8, Instancias: 328, Cobertura: 97.87%\n",
      "Número de etiquetas: 9, Instancias: 154, Cobertura: 98.05%\n",
      "Número de etiquetas: 10, Instancias: 65, Cobertura: 98.46%\n",
      "Número de etiquetas: 11, Instancias: 26, Cobertura: 96.15%\n",
      "Número de etiquetas: 12, Instancias: 7, Cobertura: 100.00%\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "num_labels, num_instances, coverage = each_size_coverage(test_pred_sets, test_true_labels)\n",
    "for l, i, c in zip(num_labels, num_instances, coverage):\n",
    "    print(f\"Número de etiquetas: {l}, Instancias: {i}, Cobertura: {(c*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a01d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c3725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7eac03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
