\chapter{Métricas de regresión}

Existen numerosas 
métricas para evaluar el rendimiento en problemas de regresión, pero tres destacan especialmente por ser 
\textit{model-agnostic}, es decir, aplicables a cualquier modelo de regresión independientemente del algoritmo 
subyacente. Estas son:

\begin{itemize}
    \item El \textbf{error absoluto medio (\textit{mean absolute error}, MAE)} mide el promedio de las 
    diferencias absolutas entre los valores reales ($Y_i$) y los valores predichos ($\hat{Y_i}$) por el 
    modelo.

    $$
    MAE = \frac{1}{n} \sum_{i=1}^n{|Y_i - \hat{Y_i}|}
    $$

    donde $n$ es el número de ejemplos/instancias con las que se cuenta en los datos a evaluar.

    La interpretación más inmediata de esta métrica es que representa cuánto se desvía en promedio la 
    predicción del valor real sin considerar la dirección del error (positivo o negativo) y, por tanto, cuanto 
    más se acerque a cero el valor, mejor es el ajuste del modelo.

    Existe una variante denominada \textbf{error absoluto mediano (\textit{median absolute error}, MedAE)}, 
    que realiza la mediana de las diferencias absolutas, en vez de la media, aumentando la robustez frente a 
    valores atípicos con errores extremos.

    \item El \textbf{error cuadrático medio (\textit{mean squared error}, MSE)} mide el promedio de los 
    errores al cuadrado entre valores reales ($Y_i$) y los valores predichos ($\hat{Y_i}$) por el modelo.
    
    $$
    MSE = \frac{1}{n} \sum_{i=1}^n{(Y_i - \hat{Y_i})^2}
    $$

    Al igual que el MAE, cuantifica qué tan cerca están las predicciones de los valores reales, pero penaliza
    más los errores grandes, y es más sensible por tanto a valores atípicos.

    Como veremos más tarde, esta métrica es muy útil en optimización mediante gradiente descendente, usado a 
    la hora de entrenar modelos de regresión basados en redes neuronales.

    Y también tiene una variante, la \textbf{raíz del error cuadrático medio (\textit{root mean square error}, 
    RMSE)}, que se obtiene extrayendo la raíz cuadrada del MSE:

    $$
    RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n}{(Y_i-\hat{Y_i})^2} }
    $$

    Esta métrica conserva las mismas unidades que la variable objetivo, lo que facilita su interpretación 
    práctica. Es comparable con el MAE en cuanto a escala, aunque sigue penalizando más los errores grandes.

    \item El \textbf{coeficiente de determinación}, o más conocido como \textbf{R² o bondad de ajuste}, mide 
    la proporción de la variabilidad de la variable dependiente ($Y$) que es explicada por el modelo.

    $$
    R^2 = 1 - \frac{\sum_{i=1}^n (Y_i - \hat{Y}_i)^2}{\sum_{i=1}^n (Y_i - \bar{Y})^2}
    $$

    donde 

    \begin{itemize}

        \item $Y_i$ es el valor real de la variable dependiente para la instancia $i$,
        
        \item $\hat{Y_i}$ es la predicción generada por el modelo, y
        
        \item $\bar{Y}$ es el promedio de los valores reales de la variable dependiente a lo largo de todas 
        las instancias del conjunto de datos.
    
    \end{itemize}
    

    El valor de esta métrica varía entre $-\infty$ y 1, y su interpretación es la siguiente:

    \begin{itemize}

        \item $R^2 \le 0$ significa que el modelo no explica ninguna variabilidad y que las predicciones del 
        modelo no son mejores que simplemente predecir la media de los valores reales.
        
        \item $R^2 \in \left(0,1\right)$ indica que el modelo está explicando una fracción de la variabilidad 
        de los datos, y cuanto más cercano sea a 1, mejor será el ajuste del modelo.
        
        \item $R^2 = 1$ indica un ajuste perfecto y, por tanto, el modelo explica toda la variabilidad de los 
        datos. 
    
    \end{itemize}

    A diferencia de las anteriores, es una métrica relativa y adimensional, es decir, no depende de las 
    unidades de la variable objetivo y evalúa qué tan bien se ajusta el modelo en comparación con un modelo 
    base que siempre predice la media de los valores reales.
    
\end{itemize}

% Elementos visuales

No obstante, el uso exclusivo de métricas numéricas resulta en un análisis pobre, ya que estas no permiten 
identificar patrones ocultos, detectar relaciones no lineales ni distinguir entre errores positivos o 
negativos. Por esta razón, se recomienda completar el análisis con representaciones gráficas, tales como:

\begin{itemize}

    \item La \textbf{gráfica de puntos de valores reales vs. predichos}, que permite visualizar la relación 
    entre las predicciones del modelo y los valores reales. Idealmente, los puntos deberían alinearse 
    alrededor de la recta $Y=\hat{Y}$. Desviaciones sistemáticas indican sesgos o problemas de ajuste. Un 
    ejemplo de esta gráfica lo encontramos en la Figura \ref{fig:scatter_pred_vs_act_AE}.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.5\textwidth]{capitulos/cap_02/imagenes/scatterplot_pred_vs_act_AE.png}
        \caption[
            Gráfica de puntos de valores de edad reales vs. predichos obtenidos por el modelo propuesto 
            en \cite{heinrich2024}.
        ]{
            Gráfica de puntos de valores de edad reales vs. predichos obtenidos por el modelo propuesto 
            en \cite{heinrich2024}. Se observan valores más dispersos en edades avanzadas.
        } 
        \label{fig:scatter_pred_vs_act_AE}
    \end{figure}

    \item También existe una versión más refinada de presentar esta información, especialmente útil en casos 
    en los que muchos datos sobrecargan la gráfica, en \textbf{la gráfica de cajas (en inglés 
    \textit{boxplot}) de valores reales vs. predichos}. Estos proporcionan una visión clara de la distribución 
    de los datos, con mediana, cuartiles y valores atípicos, ya sea agrupando por valores reales o por valores 
    predichos.

    La Figura \ref{fig:boxplot_pred_vs_act_AE} muestra la distribución de las edades predichas en función de 
    distintos grupos de edad real, y viceversa, lo que facilita la identificación de errores en el desempeño 
    del modelo.

    \begin{figure}[h]
        \centering
    
        \begin{subfigure}[b]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{capitulos/cap_02/imagenes/boxplot_pred_vs_act_AE_1.png}
            \caption{Gráfica de cajas de edades reales en función de la estimada}
            \label{fig:boxplot_pred_vs_act_AE_a}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{capitulos/cap_02/imagenes/boxplot_pred_vs_act_AE_2.png}
            \caption{Gráfica de cajas de edades estimadas en función de la real}
            \label{fig:boxplot_pred_vs_act_AE_b}
        \end{subfigure}
    
        \caption[
            Gráfica de cajas de valores de edad reales vs. predichos obtenidos por el modelo propuesto en 
            \cite{stepanovsky2024}.
        ]{
            Gráfica de cajas de valores de edad reales vs. predichos obtenidos por el modelo propuesto en 
            \cite{stepanovsky2024}. Se observa en \ref{sub@fig:boxplot_pred_vs_act_AE_b} que se sobreestima 
            la edad en personas jóvenes y se subestima 
            en personas de edad avanzada.
        }
        \label{fig:boxplot_pred_vs_act_AE}
    \end{figure}

    \item El \textbf{histograma de residuos} muestra la distribución de los errores (\(Y_i - \hat{Y}_i\)) del 
    modelo. Una distribución simétrica y centrada en cero sugiere un buen ajuste, mientras que una 
    distribución sesgada o asimétrica podría indicar que el modelo está subajustado o que hay algún patrón no 
    capturado por el modelo. 

    Un ejemplo de este tipo de gráfica lo encontramos en la Figura \ref{fig:prob_dist_AEerror}, donde se 
    analizaba el error obtenido con el modelo propuesto en \cite{stepanovsky2024}.

    Histograma de errores residuales del modelo de regresión propuesto en \cite{verma2020} que predice la 
    estatura a partir de la longitud de la tibia.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.8\textwidth]{capitulos/cap_02/imagenes/prob_distribution_AEerror.png}
        \caption[
            Histograma de errores residuales del modelo de estimación de edad propuesto en 
            \cite{stepanovsky2024}.
        ]{
            Histograma de errores residuales del modelo de estimación de edad propuesto en 
            \cite{stepanovsky2024}. Se evidencia una mayor probabilidad de errores negativos 
            (infraestimaciones) en comparación con los positivos Además, se destaca que el 57\% de las 
            predicciones presentan un error inferior al $\textnormal{MAE}$, y que el 90\% se encuentra dentro 
            de un margen de error menor a $2\textnormal{MAE}$.
        } 
        \label{fig:prob_dist_AEerror}
    \end{figure}


    \item Y una versión más completa que este último es la \textbf{gráfica de cajas de la distribución del 
    error en base a los valores reales o predichos}, que permite analizar cómo varía el error del modelo a lo 
    largo de diferentes rangos de valores, ya sean reales o predichos. Estas visualizaciones nos permiten 
    detectar fácilmente las fortalezas y debilidades en las predicciones del modelo, así como diagnosticar 
    sesgo o insuficiencia de datos en ciertas categorías.
    
    Un ejemplo ilustrativo de esta gráfica se presenta en la Figura \ref{fig:boxplot_error_vs_act_AE}, donde 
    se observa la variación del error del modelo propuesto en \cite{heinrich2024} a través de distintos rangos 
    de edad real. En particular, se evidencia una tendencia a cometer errores mayores en los grupos de edad 
    más avanzada.

    \begin{figure}[h]
        \centering
        \includegraphics[width=0.95\textwidth]{capitulos/cap_02/imagenes/boxplot_error_vs_act_AE.png}
        \caption{
            Gráfica de cajas de la distribución del error de estimación de edad en función de la edad 
            real, obtenida en el modelo propuesto en \cite{heinrich2024}.
        } 
        \label{fig:boxplot_error_vs_act_AE}
    \end{figure}

\end{itemize}